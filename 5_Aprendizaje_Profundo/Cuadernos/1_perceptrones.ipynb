{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c975b4-d0e3-4a6e-a2e8-97cb93533481",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #FECB05; text-align: center;\"> Perceptrones</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765cf802-df57-48dc-b02a-a0639c2cd664",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #007ACC;\">Autores</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7aec1-54e8-4502-a013-7a115016c56a",
   "metadata": {},
   "source": [
    "- [Juan Felipe Contreras Alcívar](https://www.linkedin.com/in/juanf-contreras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172eb970-cc5b-49a7-b305-bf3f5835cde2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487389c5-3114-4651-924a-ca1f18919280",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #007ACC;\">Tabla de contenido</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb5f01-4f36-4f62-98b3-d18621928098",
   "metadata": {},
   "source": [
    "- [<span style=\"color: #005C99;\">Introducción</span>](#introduction)\n",
    "- [<span style=\"color: #005C99;\">Proceso matemático</span>](#dim-curse)\n",
    "- [<span style=\"color: #005C99;\">Consideraciones</span>](#reference)\n",
    "- [<span style=\"color: #005C99;\">Variaciones del análisis de componentes principales</span>](#reference)\n",
    "- [<span style=\"color: #005C99;\">Referencias</span>](#reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078b10a-0e3e-4f7c-800e-bcd43d2b2b57",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10aedc7-fc3e-4971-be4e-c78e902a1312",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #007ACC;\"> Introducción </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db6ad9-2420-4331-a2b5-d776a497efa1",
   "metadata": {},
   "source": [
    "El perceptrón es un concepto fundamental en el campo de la inteligencia artificial, específicamente en el área del aprendizaje automático y las redes neuronales. Fue introducido por Frank Rosenblatt en 1958 y es considerado uno de los primeros modelos de redes neuronales artificiales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53d2c7-24dc-4622-8251-dd19a282a9e9",
   "metadata": {},
   "source": [
    "<h3 id=\"subsection1-1\" style=\"color: #003366;\">¿Qué es un Perceptrón?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4c95c-286e-4250-9851-646f83c9aa1c",
   "metadata": {},
   "source": [
    "Un perceptrón es una unidad de procesamiento que emula la forma en que las neuronas biológicas procesan la información. Básicamente, un perceptrón toma varias entradas binarias o continuas, las pondera, y luego genera una salida también binaria (0 o 1) basada en una función de activación. Esta salida indica si el perceptrón \"activa\" o \"no activa\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb1bca-1281-4f6e-995b-9655c5c7e28c",
   "metadata": {},
   "source": [
    "<h3 id=\"subsection1-1\" style=\"color: #003366;\">Componentes del Perceptrón</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0761cca6-d074-4326-9643-2f8903c538c8",
   "metadata": {},
   "source": [
    "1. **Entradas (Input):** Son los valores que se introducen al perceptrón. Cada entrada tiene un peso asociado que se ajusta durante el proceso de entrenamiento.\n",
    "2. **Pesos (Weights):** Son coeficientes que multiplican cada una de las entradas. Inicialmente, estos pesos se asignan aleatoriamente y se ajustan durante el aprendizaje.\n",
    "3. **Bias:** Es un valor adicional que se suma a la entrada ponderada antes de aplicar la función de activación. Ayuda a mover la función de activación hacia la izquierda o la derecha, mejorando la capacidad del modelo para ajustarse a los datos.\n",
    "4. **Función de Activación:** Es una función matemática que toma la suma ponderada de las entradas y el bias, y genera la salida del perceptrón. En el perceptrón original, la función de activación es una función escalón (o Heaviside), que produce 1 si la entrada ponderada supera un umbral determinado, y 0 en caso contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbbae35-31dd-4a26-b813-122d99fa0b7a",
   "metadata": {},
   "source": [
    "<h3 id=\"subsection1-1\" style=\"color: #003366;\">Funcionamiento del Perceptrón</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7316ca-7e67-4389-b4be-51724e54100c",
   "metadata": {},
   "source": [
    "1. **Inicialización:** Se asignan valores iniciales a los pesos y al bias.\n",
    "2. **Cálculo de la salida:** Para una entrada dada, se calcula la salida sumando todas las entradas multiplicadas por sus respectivos pesos y luego sumando el bias. Esta suma se pasa a través de la función de activación para producir la salida final.\n",
    "3. **Actualización de pesos:** Si la salida calculada no coincide con la salida deseada (etiqueta), se ajustan los pesos y el bias para reducir el error. Este proceso se repite para muchas iteraciones, lo que permite al perceptrón aprender de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3adf4c-2ec1-42d4-8bee-57364577a4fb",
   "metadata": {},
   "source": [
    "<h3 id=\"subsection1-1\" style=\"color: #003366;\">Aplicaciones del Perceptrón</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cc57c-6cf7-41d3-ba70-93a93cc992eb",
   "metadata": {},
   "source": [
    "El perceptrón se utiliza principalmente en problemas de clasificación binaria, donde se desea separar dos clases diferentes. Aunque es un modelo muy simple y tiene limitaciones, especialmente cuando se trata de problemas no lineales, ha sentado las bases para el desarrollo de redes neuronales más complejas y profundas, como las redes neuronales multicapa (MLP) y las redes neuronales convolucionales (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646b838-a3c0-4f26-bd16-fbd348f0eb88",
   "metadata": {},
   "source": [
    "<h3 id=\"subsection1-1\" style=\"color: #003366;\">Limitaciones del Perceptrón</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42988b3e-dccf-4ead-b29d-7af6eb88af13",
   "metadata": {},
   "source": [
    "Una de las principales limitaciones del perceptrón es que solo puede resolver problemas linealmente separables. Esto significa que si los datos no pueden separarse con una línea recta (o un hiperplano en dimensiones superiores), el perceptrón no podrá clasificarlos correctamente. Este problema fue formalmente demostrado por Minsky y Papert en 1969, lo que llevó al desarrollo de modelos más avanzados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d363f63-3cd3-47a1-b224-2b1f4cbe6414",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #007ACC;\">Perceptrón de una capa</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f653aaf-36a5-451d-9c6e-01dfc2ba02be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3816b35c-722d-4b3e-8f14-552e6d286d0b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301798d1-71a6-4f9f-8731-384433890cfb",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #007ACC;\">Perceptrón multicapa</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e9b9d-21a9-408d-a97c-2dead066469a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad4636-48e8-48b9-9464-fc2993c4eb6f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc8a96-aa80-48f7-92e7-5f40f065a01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
